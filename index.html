<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  
  <title>Cloud</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="To reach the target of being a better person.">
<meta property="og:type" content="website">
<meta property="og:title" content="Cloud">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Cloud">
<meta property="og:description" content="To reach the target of being a better person.">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Cloud">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Cloud" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Cloud</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-结合注意力卷积神经网络的图像检索技术研究" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2021/12/22/%E7%BB%93%E5%90%88%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/" class="article-date">
  <time datetime="2021-12-22T10:58:09.000Z" itemprop="datePublished">2021-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/12/22/%E7%BB%93%E5%90%88%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/">论文阅读-《结合注意力卷积神经网络的图像检索技术研究》</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><em>引用：</em>[1]魏赟,严正怡.结合注意力卷积神经网络的图像检索技术研究[J].小型微型计算机系统,2021,42(11):2368-2374.</p>
<hr>
<h4 id="摘要："><a href="#摘要：" class="headerlink" title="摘要："></a>摘要：</h4><ul>
<li>针对基于CNN的图像检索系统对图像特征表达力不足、缺乏准确率和鲁棒性，提出结合注意力卷积神经网络的图像检索技术；</li>
<li>针对基础VGG-16缺少BN层、池化对局部的忽视、改进影响速度等因素，加入BN计算、替换Max-pooling层、渐少FC层，并行加入串行注意力模型(CS-Attention)实现对特征向量加权重构；</li>
<li>通过计算所要检索图像与图像库中图像的余弦相似度，得出相似图像。</li>
</ul>
<hr>
<h4 id="引言："><a href="#引言：" class="headerlink" title="引言："></a>引言：</h4><p>1.加入BN操作可以提升收敛速度；</p>
<p>2.通过PCA压缩和反诉训练可提升特征提取性能；</p>
<p>3.由于改进单对模型不满足检索精度和速率的要求，融合注意力模型开始成为研究热点；</p>
<p><strong>本文在基础模型VGG-16上进行改进，VGG-16模型缺少BN层，因此在ReLU计算前加入BN层，使得卷积后特征呈正态分布；为了映射图像关键位置、提升准确率，并行CS-Attention注意力模型，使得卷积后的特征向量得以重构。经过多次卷积和池化，进入替换的Mean-pooling和增加的SP金字塔池化，可以更多地保留次要元素、增强通用性；为了弥补之前的时间损失，再进入简化的全连接层，从而提高图像特征提取速度。</strong></p>
<hr>
<h4 id="相关工作："><a href="#相关工作：" class="headerlink" title="相关工作："></a>相关工作：</h4><ul>
<li><p>CNN核心卷积层输出的特征运算公式：<br>$$<br>C^k_j= f(∑^{count(N_j)}<em>{i∈N_j}w^k</em>{ij}×C^{k－1}_i+ b^k_j)<br>$$<br>其中k为层数，Ckj为第k层的第j个特征图，f(×)为ReLU激活函数，Nj为输入卷积层的特征图，count(Nj)为特征图个数，w为卷积核，×为卷积运算，b为偏置项．</p>
</li>
<li><p>注意力模型可以在全局图像中寻找关键的目标信息，忽略无用信息，与CNN结合生成图像显著区。</p>
</li>
</ul>
<hr>
<h4 id="算法框架："><a href="#算法框架：" class="headerlink" title="算法框架："></a>算法框架：</h4><p><img src="https://github.com/lbycan/ImageData/blob/main/%E5%9F%BA%E4%BA%8ECNN%E7%9A%84%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2%E6%B5%81%E7%A8%8B.jpg?raw=true"></p>
<ul>
<li>图像预处理：大小处理为224x224，去均值处理，从RGB三维度减去其均值，将图像数据中心化为0，防止拟合；归一化处理，计算RGB最值，将图像数据压缩在0-1之间，提高收敛度；<br>$$<br>去均值化：X^i_j= X^i_j－1/m∑^m_{j =1}X^i_j<br>$$</li>
</ul>
<p>$$<br>  归一化：X^i_j=［X^i_j－ min(X^i_j) ］/［max(X^i_j)－ min(X^i_j) ］<br>$$</p>
<ul>
<li><p>加入BN层，VGG-N模型的卷积操作实际变成CONV+BN+ReLU；<br>$$<br>BN层引入可学习参数γ和β：γ(h)，β(h)=\sqrt{var［x^h］}，E［x(k)］<br>$$</p>
</li>
<li><p>替换Max-pooling：在ILS-VRC数据集用VGG-16模型，最后一层池化层替换成Mean-pooling能够降低邻域大小造成的误差、更多保留图像背景，从而提升检索精度，而Max-pooling仅仅偏向于降低卷积参数造成的误差。</p>
</li>
<li><p>加入空间金字塔池化层：为了增强模型的通用性和鲁棒性，在全连接层前面加入SP金字塔池化层．此时图像以不同大小进入VGG-N模型中，仍可以固定大小进入全连接层，这样增加了模型的鲁棒性；</p>
</li>
<li><p>减少全连接层：越靠近顶层的操作对图像特征提取影响越小，为了减少网络计算量、提升训练速率，删除前两层FC，保留最后一层FC</p>
</li>
<li><p>串行注意力模型：本文注意力模型是由通道注意力模块和空间注意力模块串行组合而成的串行注意力模型(CS-Attention)，串行的先通道后空间注意力模型的检索错误率最低；</p>
<p><strong>通道注意力模块过程：</strong>(1)中间特征图经过最大池化、平均池化和随机池化得到相同维度的多个具有全局意义的实数；(2)进入共享网络，减少不同通道的查一下，得到3个MLP操作后的向量；(3)3个向量各元素相加组成一维向量，用ReLU函数归一化到0-1范围；(4)对输入的特征图的通道进行加权；</p>
<p><strong>空间注意力模块过程：</strong>(1)用Stochastic-pooling、Max-pooling和Mean-pooling这3种池化进行降维，得到3个特征矩阵$K^S_sto$、$K^S_avg$、$K^S_max$;(2)将输出的3个特征矩阵合成一个，进行Conv操作，得到卷积后的注意力特征图；(3)用ReLU函数得到经过空间注意力模块、范围为0-1的注意力图；(4)对输入特征的空间加权</p>
<p><img src="https://github.com/lbycan/ImageData/blob/main/%E4%B8%B2%E8%A1%8C%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B.jpg?raw=true"></p>
</li>
<li><p><strong>注意力卷积神经网络(VGG-NA)：</strong></p>
<p>VGG-NA模型由VGG-N模型和CS-Attention模型并行组合而成，其中VGG-N模型(如图3(A)为VGG-N的一个模<br>块)为用于特征提取的CNN基础模型，CS-Attention模型为用于加权的注意力模型，CS-Attention模型被应用于全网VGG-N模型。图像数据集经过预处理进入VGG-NA模型进行训练，池化前的中间特征向量由两部分相乘得到:第1部分是<strong>多组CONV + BN + ReLU的卷积操作</strong>，其中卷积核为3 ×3、步长为1；第2部分是<strong>CS-Attention注意力模型</strong>加权映射．之后送入<strong>池化层</strong>，包括4个Max-pooling池化层、1个Mean-poo-ling池化层和1个SP金字塔池化层。最后经过<strong>1个FC层和Softmax分类函数</strong>，完成特征提取。</p>
<p><img src="https://github.com/lbycan/ImageData/blob/main/VGG-NA%E6%A8%A1%E5%9E%8B.jpg?raw=true"></p>
</li>
<li><p>相似性检索算法：本文通过向量表示经训练模型VGG-NA提取的图像特征，因此选取余弦相似度算法(Cosine Similarity)来计算向量夹角的余弦值，比较图像相似度．余弦值越接近1，夹角越接近0，相似度越高。</p>
</li>
</ul>
<hr>
<h4 id="实验于分析："><a href="#实验于分析：" class="headerlink" title="实验于分析："></a>实验于分析：</h4><ul>
<li>数据集：Corel-1000和Corel5K图像集；</li>
<li>使用一种基于排名的评价标准；</li>
<li>使用高斯分布随机产生权值，去除Dropout层、加入BN层防止过拟合，$L_2$惩罚系数为0.0001，mini-batch为256，梯度下降动量为0.9，初始学习率为0.002，学习率衰减为0.9</li>
</ul>
<hr>
<h4 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h4><ul>
<li>对基础网络模型VGG-16的改进，在CONV和ReLU之间加入BN计算、替换Max-pooling为Mean-pooling、增加SP金字塔池化、简化FC层，得到新模型VGG-N；</li>
<li>对注意力模型的改进，在串行的空间和通道注意力模型的池化部分加入stochastic-pooling，得到新串行注意力模型CS-Attention；</li>
<li>将VGG-N模型与CS-Attention模型并行加权融合，重构特征向量，得到本文VGG-NA模型。</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/12/22/%E7%BB%93%E5%90%88%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/" data-id="ckya0walb000130vm2nhfagp7" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/" rel="tag">图像检索</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-图像检索" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2021/12/22/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/" class="article-date">
  <time datetime="2021-12-22T06:45:35.000Z" itemprop="datePublished">2021-12-22</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/12/22/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/">图像检索Image Retrieval</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <hr>
<p>给定一个包含特定实例(例如特定目标、场景、建筑等)的查询图像，图像检索旨在从数据库图像中找到包含相同实例的图像。但由于不同图像的拍摄视角、光照、或遮挡情况不同，如何设计出能应对这些类内差异的有效且高效的图像检索算法仍是一项研究难题。</p>
<p><strong>检索分类：</strong></p>
<ul>
<li><p>基于文本的图像检索(ext-based Image Retrieval，简称TBIR)：利用文本描述的方式描述图像的特征，如图像名称、图像尺寸、压缩类型、作者、年代等方面标引图像，一般以关键词形式的提问查询图像，或者事根据等级目录的形式浏览查找特定类目下的图像。</p>
</li>
<li><p>基于内容的图像检索(Content-based Image Retrieval，简称CBIR)：根据图像、图像的内容语义以及上下文联系进行查找，以图像予以特征为线索从图像数据库中检出具有相似特性的其他图像，如图像的颜色、纹理、布局等。</p>
</li>
</ul>
<p><strong>图像检索包括三方面：</strong> </p>
<ul>
<li>对用户需求的分析和转化，形成可以检索索引数据库的提问；</li>
<li>收集和加工图像资源，提取特征，分析并进行标引，建立图像的索引数据库；</li>
<li>根据相似度算法，计算用户提问与索引数据库中记录的相似度大小，提取处满足阈值的记录作为结果，按照相似度降序的方式输出。</li>
</ul>
<p><strong>检索方法：</strong></p>
<p>关键词查找、浏览查找、特征输入查找、草图查找、示例查询；</p>
<p>图像特征的三个层次：可视化特征层次、对象层次、抽象的特征层次。</p>
<p><strong>检索步骤：</strong></p>
<p>输入图片、特征提取、度量学习、重排序。</p>
<ul>
<li><p>特征提取：即将图片数据进行降维，提取数据的判别性信息，一般将一张图片降维成一个向量；</p>
</li>
<li><p>度量学习：一般利用度量函数，计算图片特征之间的距离作为loss，训练特征提取网络，使得相似图片提取的特征相似，不同类的图片提取的特征差异性较大；</p>
</li>
<li><p>重排序：利用数据间的流形关系，对度量结果进行重新排序，从而得到更好的检索结果。</p>
</li>
</ul>
<p>从图像中提取一个合适的图像的表示向量→对这些表示向量用欧式距离或余弦距离进行最近邻搜索以找到相似的图像→可以使用一些后处理技术对检索结果进行微调。</p>
<p><strong>决定一个图像检索算法性能的关键在于提取的图像表示的好坏。</strong></p>
<blockquote>
<p><img src="https://t11.baidu.com/it/u=354698902,2043467629&fm=173&app=49&f=JPEG?w=640&h=267&s=49967D928C30DF9A505DA856020080F3" alt="图像检索流程"></p>
</blockquote>
<p><img src="https://github.com/lbycan/ImageData/blob/main/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2%E7%AC%94%E8%AE%B01.PNG?raw=true"></p>
<p><img src="https://github.com/lbycan/ImageData/blob/main/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2%E7%AC%94%E8%AE%B02.PNG?raw=true"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/12/22/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/" data-id="ckya0wal5000030vm77660dj4" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/" rel="tag">图像检索</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-论文阅读-基于改进YOLOv5s的交通信号灯识别方法研究" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2021/12/21/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BYOLOv5s%E7%9A%84%E4%BA%A4%E9%80%9A%E4%BF%A1%E5%8F%B7%E7%81%AF%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6/" class="article-date">
  <time datetime="2021-12-21T07:44:47.000Z" itemprop="datePublished">2021-12-21</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/12/21/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BYOLOv5s%E7%9A%84%E4%BA%A4%E9%80%9A%E4%BF%A1%E5%8F%B7%E7%81%AF%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6/">论文阅读-基于改进YOLOv5s的交通信号灯识别方法研究</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <hr>
<blockquote>
<p>单阶段目标检测方法：指只需进行一次特征提取即可实现目标检测，其速度相比多阶段的算法快，但一般精度稍低一些。常用算法有：Yolo系列、SSD、RetinaNet。</p>
<p>多阶段目标检测方法：常用算法有：RCNN、Fast RCNN、Faster RCNN、Cascade RCNN、Mask RCNN。</p>
<p>旋转目标检测：旋转目标检测与水平目标检测不同，需要检测目标的方向，在遥感图像目标检测、文字检测等任务中比较常见。预测的结果包含类别、位置坐标、长宽、角度。常用算法有：Rol Transformer。</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/12/21/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BYOLOv5s%E7%9A%84%E4%BA%A4%E9%80%9A%E4%BF%A1%E5%8F%B7%E7%81%AF%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6/" data-id="ckya0walg000330vm2zc9e4cs" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag">目标检测</a></li></ul>

    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/" rel="tag">图像检索</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" rel="tag">目标检测</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/" style="font-size: 20px;">图像检索</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 10px;">目标检测</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">十二月 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/12/22/%E7%BB%93%E5%90%88%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6/">论文阅读-《结合注意力卷积神经网络的图像检索技术研究》</a>
          </li>
        
          <li>
            <a href="/2021/12/22/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/">图像检索Image Retrieval</a>
          </li>
        
          <li>
            <a href="/2021/12/21/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BYOLOv5s%E7%9A%84%E4%BA%A4%E9%80%9A%E4%BF%A1%E5%8F%B7%E7%81%AF%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6/">论文阅读-基于改进YOLOv5s的交通信号灯识别方法研究</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2022 Cloud<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>




  </div>
</body>
</html>